# Evaluation Framework Setup Complete âœ…

## What Was Created

### Directory Structure

```
evals/
â”œâ”€â”€ README.md                          # Main overview
â”œâ”€â”€ framework/                         # Reusable evaluation framework
â”‚   â”œâ”€â”€ README.md                      # Framework documentation
â”‚   â”œâ”€â”€ package.json                   # Dependencies
â”‚   â”œâ”€â”€ tsconfig.json                  # TypeScript config
â”‚   â”œâ”€â”€ .gitignore                     # Git ignore rules
â”‚   â””â”€â”€ src/                           # Source code (empty, ready for implementation)
â”‚       â”œâ”€â”€ collector/                 # Session data collection
â”‚       â”œâ”€â”€ evaluators/                # Evaluation logic
â”‚       â”œâ”€â”€ runner/                    # Test execution
â”‚       â”œâ”€â”€ reporters/                 # Result reporting
â”‚       â””â”€â”€ types/                     # TypeScript types
â”‚
â”œâ”€â”€ opencode/                          # OpenCode agent evaluations
â”‚   â”œâ”€â”€ openagent/                     # OpenAgent-specific tests
â”‚   â”‚   â”œâ”€â”€ README.md                  # OpenAgent test documentation
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ config.yaml            # OpenAgent configuration
â”‚   â”‚   â”œâ”€â”€ test-cases/                # Test case definitions (empty)
â”‚   â”‚   â””â”€â”€ sessions/                  # Recorded test sessions (empty)
â”‚   â””â”€â”€ shared/                        # Shared test cases (empty)
â”‚
â””â”€â”€ results/                           # Test results (gitignored)
    â””â”€â”€ .gitkeep
```

### Task Documentation

```
tasks/eval-framework/
â”œâ”€â”€ README.md                          # Project overview
â”œâ”€â”€ 01-session-reader.md               # Task 1: Session Reader
â”œâ”€â”€ 02-evaluators.md                   # Task 2: Core Evaluators
â””â”€â”€ 03-test-runner.md                  # Task 3: Test Runner
```

### Configuration Files

1. **Framework Package** (`evals/framework/package.json`)
   - TypeScript setup
   - Testing with Vitest
   - Build scripts
   - Linting

2. **OpenAgent Config** (`evals/opencode/openagent/config/config.yaml`)
   - Evaluator settings
   - Scoring weights
   - Rule definitions
   - Model preferences

3. **Git Ignore** (`.gitignore`)
   - Results directory ignored
   - Node modules ignored
   - Build artifacts ignored

---

## Next Steps

### Phase 1: Foundation (Start Here)

**Goal:** Build session reader and basic types

**Tasks:**
1. Implement TypeScript types (`framework/src/types/index.ts`)
2. Implement SessionReader (`framework/src/collector/session-reader.ts`)
3. Implement MessageParser (`framework/src/collector/message-parser.ts`)
4. Implement TimelineBuilder (`framework/src/collector/timeline-builder.ts`)
5. Write tests

**See:** [tasks/eval-framework/01-session-reader.md](../tasks/eval-framework/01-session-reader.md)

**Estimated Time:** 4-6 hours

---

### Phase 2: Core Evaluators

**Goal:** Implement evaluation logic

**Tasks:**
1. Implement BaseEvaluator
2. Implement ApprovalGateEvaluator
3. Implement ContextLoadingEvaluator
4. Implement DelegationEvaluator
5. Implement ToolUsageEvaluator
6. Write tests

**See:** [tasks/eval-framework/02-evaluators.md](../tasks/eval-framework/02-evaluators.md)

**Estimated Time:** 8-10 hours

---

### Phase 3: Test Runner

**Goal:** Execute test cases and generate results

**Tasks:**
1. Implement test case loader
2. Implement SessionAnalyzer
3. Implement TestRunner
4. Create test case library
5. Write tests

**See:** [tasks/eval-framework/03-test-runner.md](../tasks/eval-framework/03-test-runner.md)

**Estimated Time:** 6-8 hours

---

### Phase 4: Reporters (Future)

**Goal:** Generate useful reports

**Tasks:**
1. Implement ConsoleReporter
2. Implement JSONReporter
3. Implement MarkdownReporter
4. Add trend analysis

**Estimated Time:** 4-6 hours

---

## Quick Start

### 1. Install Dependencies

```bash
cd evals/framework
npm install
```

### 2. Start Building

Begin with Phase 1 - Session Reader:

```bash
# Create types file
touch src/types/index.ts

# Create session reader
touch src/collector/session-reader.ts

# Create message parser
touch src/collector/message-parser.ts

# Create timeline builder
touch src/collector/timeline-builder.ts
```

### 3. Run Tests

```bash
# Run tests
npm test

# Watch mode
npm run test:watch
```

### 4. Build

```bash
# Build TypeScript
npm run build

# Watch mode
npm run build:watch
```

---

## Architecture Overview

### Data Flow

```
OpenCode Session Storage
         â†“
    SessionReader (reads JSON files)
         â†“
    MessageParser (parses structure)
         â†“
    TimelineBuilder (builds timeline)
         â†“
    Evaluators (validate behavior)
         â†“
    TestRunner (executes tests)
         â†“
    Reporters (generate reports)
         â†“
    Results (JSON/Markdown/Console)
```

### Key Components

**Collector:**
- Reads OpenCode session data
- Parses messages and parts
- Builds chronological timeline

**Evaluators:**
- Validate agent behavior
- Check compliance with rules
- Generate scores and violations

**Runner:**
- Load test case definitions
- Execute evaluators
- Collect results

**Reporters:**
- Format results
- Generate reports
- Export data

---

## Configuration

### Framework Config

Edit `framework/src/config.ts` (to be created):

```typescript
export const config = {
  projectPath: process.cwd(),
  sessionStoragePath: '~/.local/share/opencode/',
  resultsPath: '../results/',
  passThreshold: 75,
};
```

### OpenAgent Config

Edit `opencode/openagent/config/config.yaml`:

```yaml
agent: openagent
pass_threshold: 75
scoring:
  approval_gate: 40
  context_loading: 40
  delegation: 10
  tool_usage: 10
```

---

## Testing Strategy

### Unit Tests
Test individual components in isolation:
- SessionReader
- MessageParser
- TimelineBuilder
- Each evaluator

### Integration Tests
Test components working together:
- Read real session data
- Build timeline
- Run evaluators
- Generate results

### Regression Tests
Test against recorded sessions:
- Store known-good sessions
- Run tests against them
- Detect behavior changes

---

## Documentation

### Main Docs
- [Evaluation Framework Overview](./README.md)
- [Framework Documentation](./framework/README.md)
- [OpenAgent Tests](./opencode/openagent/README.md)

### Task Breakdown
- [Project Overview](../tasks/eval-framework/README.md)
- [Task 1: Session Reader](../tasks/eval-framework/01-session-reader.md)
- [Task 2: Core Evaluators](../tasks/eval-framework/02-evaluators.md)
- [Task 3: Test Runner](../tasks/eval-framework/03-test-runner.md)

### Related Docs
- [OpenCode Logging System](../dev/ai-tools/opencode/logging-and-session-storage.md)
- [Agent Validator Plugin](../.opencode/plugin/docs/VALIDATOR_GUIDE.md)
- [OpenAgent Specification](../.opencode/agent/openagent.md)

---

## Success Criteria

### Phase 1 Complete When:
- [ ] Can read any OpenCode session
- [ ] Can parse messages and parts
- [ ] Can build complete timeline
- [ ] All types defined
- [ ] Tests pass

### Phase 2 Complete When:
- [ ] All evaluators implemented
- [ ] Can detect violations
- [ ] Scoring system works
- [ ] Tests pass

### Phase 3 Complete When:
- [ ] Can load test cases from YAML
- [ ] Can run test suites
- [ ] Can generate results
- [ ] Tests pass

### Phase 4 Complete When:
- [ ] Can generate console reports
- [ ] Can export JSON
- [ ] Can generate Markdown
- [ ] Tests pass

---

## Getting Help

- Review task documentation in `tasks/eval-framework/`
- Check OpenCode logging docs in `dev/ai-tools/opencode/`
- Examine existing session data in `~/.local/share/opencode/`
- Look at validator plugin in `.opencode/plugin/agent-validator.ts`

---

## Ready to Start!

Begin with **Phase 1: Session Reader**

See: [tasks/eval-framework/01-session-reader.md](../tasks/eval-framework/01-session-reader.md)

Good luck! ðŸš€
